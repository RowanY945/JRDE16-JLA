{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a6a96a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers.json import JsonOutputParser\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e061bf8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(dotenv_path=\"../../.env\", override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4f0c39d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def create_job_summary_prompt():\n",
    "    \"\"\"Create the prompt template for job description summarization\"\"\"\n",
    "    \n",
    "    template = \"\"\"\n",
    "    You are an expert HR professional and recruiter. Please analyze the following job description and provide a comprehensive summary in JSON format.\n",
    "\n",
    "    Job Description:\n",
    "    {job_description}\n",
    "\n",
    "    Please extract and organize the information into the following structure:\n",
    "\n",
    "    **Job Information**\n",
    "    - Extract job title from the description\n",
    "    - Determine job level based on responsibilities and requirements (Entry/Junior/Mid-level/Senior/Lead/Executive)\n",
    "\n",
    "    **Company Information**\n",
    "    - Extract company name if mentioned, otherwise use null\n",
    "    - Determine or extract industry if mentioned, otherwise use null\n",
    "\n",
    "    **Location Information**\n",
    "    - Extract city, state, country if mentioned, otherwise use null\n",
    "    - Determine work type: \"remote\", \"hybrid\", or \"on-site\"\n",
    "    - Assess remote flexibility: \"full\", \"partial\", or \"none\"\n",
    "\n",
    "    **Compensation**\n",
    "    - Extract salary information:\n",
    "      - Min salary: minimum salary as number without commas\n",
    "      - Max salary: maximum salary as number without commas\n",
    "      - If range given (e.g., \"$120,000 - $160,000\"), extract both values\n",
    "      - If single value given, use same for min and max\n",
    "      - If not mentioned, use null for both\n",
    "\n",
    "    **Overview**\n",
    "    - Provide a brief 1-2 sentence summary of the position and its primary purpose\n",
    "\n",
    "    **Responsibilities**\n",
    "    - List the 3-5 most important responsibilities/duties\n",
    "    - Focus on core functions, not minor tasks\n",
    "\n",
    "    **Requirements - Required**\n",
    "    - Skills: Extract technical skills, programming languages, platforms (no commas in values)\n",
    "    - Tools: Extract specific tools, software, applications mentioned\n",
    "    - Experience: Determine years_min, years_max (as numbers), and level (junior/mid/senior)\n",
    "    - Qualifications: List essential requirements, experience, education\n",
    "\n",
    "    **Requirements - Preferred**\n",
    "    - Skills: Extract nice-to-have technical skills and platforms\n",
    "    - Tools: Extract preferred tools and software\n",
    "    - Certifications: Extract any certifications mentioned\n",
    "    - Qualifications: List preferred experience and qualifications\n",
    "    \n",
    "\n",
    "    {format_instructions}\n",
    "    \"\"\"\n",
    "    \n",
    "    return PromptTemplate(\n",
    "        input_variables=[\"job_description\"],\n",
    "        template=template,\n",
    "        partial_variables={\"format_instructions\": \"{format_instructions}\"}\n",
    "    )\n",
    "\n",
    "class JobDescriptionSummarizer:\n",
    "    def __init__(self, model_name=\"gpt-4o-mini\", temperature=0.3):\n",
    "        \"\"\"\n",
    "        Initialize the job description summarizer\n",
    "        \n",
    "        Args:\n",
    "            model_name (str): OpenAI model to use\n",
    "            temperature (float): Temperature for text generation (0.0-2.0)\n",
    "                                0.0 = deterministic, focused responses\n",
    "                                1.0 = balanced creativity and consistency  \n",
    "                                2.0 = highly creative, unpredictable responses\n",
    "        \"\"\"\n",
    "        self.llm = ChatOpenAI(\n",
    "            model=model_name,\n",
    "            temperature=temperature\n",
    "        )\n",
    "        \n",
    "        # Define the expected JSON schema\n",
    "        \n",
    "        self.json_schema = {\n",
    "            \"job_id\": \"Job ID to be added later\",\n",
    "            \"job_title\": \"Extracted job title\",\n",
    "            \"job_level\": \"Junior/Mid-level/Senior/Lead/Executive\",\n",
    "            \"company\": {\n",
    "                \"name\": \"Company name or null\",\n",
    "                \"industry\": \"Industry type or null\"\n",
    "            },\n",
    "            \"location\": {\n",
    "                \"city\": \"City or null\",\n",
    "                \"state\": \"State or null\", \n",
    "                \"country\": \"Country or null\",\n",
    "                \"work_type\": \"remote/hybrid/on-site\",\n",
    "                \"remote_flexibility\": \"full/partial/none\"\n",
    "            },\n",
    "            \"compensation\": {\n",
    "                \"salary\": {\n",
    "                    \"min\": \"Minimum salary as number or null\",\n",
    "                    \"max\": \"Maximum salary as number or null\"\n",
    "                }\n",
    "            },\n",
    "            \"overview\": \"Brief 1-2 sentence summary\",\n",
    "            \"responsibilities\": [\"List of 3-5 key responsibilities\"],\n",
    "            \"requirements\": {\n",
    "                \"required\": {\n",
    "                    \"skills\": [\"Technical skills array\"],\n",
    "                    \"tools\": [\"Tools and software array\"],\n",
    "                    \"experience\": {\n",
    "                        \"years_min\": \"Minimum years as number\",\n",
    "                        \"years_max\": \"Maximum years as number\", \n",
    "                        \"level\": \"entry/junior/mid/senior\"\n",
    "                    },\n",
    "                    \"qualifications\": [\"Essential qualifications array\"]\n",
    "                },\n",
    "                \"preferred\": {\n",
    "                    \"skills\": [\"Preferred technical skills array\"],\n",
    "                    \"tools\": [\"Preferred tools array\"],\n",
    "                    \"certifications\": [\"Certifications array\"],\n",
    "                    \"qualifications\": [\"Preferred qualifications array\"]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Initialize JSON parser with schema\n",
    "        self.parser = JsonOutputParser(pydantic_object=None)\n",
    "        self.prompt = create_job_summary_prompt()\n",
    "        \n",
    "        # Create the chain with format instructions\n",
    "        self.chain = self.prompt.partial(format_instructions=self.parser.get_format_instructions()) | self.llm | self.parser\n",
    "    \n",
    "    def summarize(self, job_description: str) -> dict:\n",
    "        \"\"\"\n",
    "        Summarize a job description\n",
    "        \n",
    "        Args:\n",
    "            job_description (str): The full job description text\n",
    "            \n",
    "        Returns:\n",
    "            dict: Structured summary of the job description\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Generate summary using LCEL chain with JSON parser\n",
    "            result = self.chain.invoke({\"job_description\": job_description})\n",
    "            \n",
    "            return {\n",
    "                \"success\": True,\n",
    "                \"summary\": result,\n",
    "                \"raw_output\": str(result)\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"error\": str(e),\n",
    "                \"summary\": None,\n",
    "                \"raw_output\": None\n",
    "            }\n",
    "    \n",
    "    def summarize_from_parquet(self, parquet_file_path: str, job_id, id_column=\"id\", jd_column=\"JD\") -> dict:\n",
    "        \"\"\"\n",
    "        Summarize a specific job description from a parquet file by job ID\n",
    "        \n",
    "        Args:\n",
    "            parquet_file_path (str): Path to the parquet file containing job descriptions\n",
    "            job_id: The specific job ID to process\n",
    "            id_column (str): Name of the ID column (default: \"id\")\n",
    "            jd_column (str): Name of the job description column (default: \"JD\")\n",
    "            \n",
    "        Returns:\n",
    "            dict: Structured summary of the job description\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Read parquet file\n",
    "            df = pd.read_parquet(parquet_file_path)\n",
    "            \n",
    "            # Validate columns exist\n",
    "            if id_column not in df.columns:\n",
    "                return {\n",
    "                    \"success\": False,\n",
    "                    \"error\": f\"Column '{id_column}' not found in parquet file. Available columns: {list(df.columns)}\",\n",
    "                    \"summary\": None,\n",
    "                    \"job_id\": job_id\n",
    "                }\n",
    "            \n",
    "            if jd_column not in df.columns:\n",
    "                return {\n",
    "                    \"success\": False,\n",
    "                    \"error\": f\"Column '{jd_column}' not found in parquet file. Available columns: {list(df.columns)}\",\n",
    "                    \"summary\": None,\n",
    "                    \"job_id\": job_id\n",
    "                }\n",
    "            \n",
    "            # Find the specific job ID\n",
    "            job_row = df[df[id_column] == job_id]\n",
    "            \n",
    "            if job_row.empty:\n",
    "                return {\n",
    "                    \"success\": False,\n",
    "                    \"error\": f\"Job ID '{job_id}' not found in the parquet file\",\n",
    "                    \"summary\": None,\n",
    "                    \"job_id\": job_id\n",
    "                }\n",
    "            \n",
    "            # Get the job description\n",
    "            job_description = str(job_row[jd_column].iloc[0])\n",
    "            \n",
    "            # Check if job description is empty or NaN\n",
    "            if pd.isna(job_description) or job_description.strip() == \"\" or job_description.lower() == \"nan\":\n",
    "                return {\n",
    "                    \"success\": False,\n",
    "                    \"error\": f\"Job description is empty or missing for ID '{job_id}'\",\n",
    "                    \"summary\": None,\n",
    "                    \"job_id\": job_id\n",
    "                }\n",
    "            \n",
    "            print(f\"Processing Job ID: {job_id}\")\n",
    "            print(f\"Job Description Length: {len(job_description)} characters\")\n",
    "            \n",
    "            # Summarize the job description\n",
    "            summary_result = self.summarize(job_description)\n",
    "            \n",
    "            # Add job ID to the result\n",
    "            summary_result[\"job_id\"] = job_id\n",
    "            \n",
    "            return summary_result\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"error\": f\"Parquet file not found: {parquet_file_path}\",\n",
    "                \"summary\": None,\n",
    "                \"job_id\": job_id\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"error\": f\"Error processing parquet file: {str(e)}\",\n",
    "                \"summary\": None,\n",
    "                \"job_id\": job_id\n",
    "            }\n",
    "\n",
    "def print_job_summary(summary_result: dict):\n",
    "    \"\"\"Pretty print the job summary result in JSON format\"\"\"\n",
    "    \n",
    "    if not summary_result[\"success\"]:\n",
    "        print(f\"❌ Error for Job ID {summary_result.get('job_id', 'Unknown')}: {summary_result['error']}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"📋 JOB DESCRIPTION SUMMARY - ID: {summary_result.get('job_id', 'Unknown')}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    summary = summary_result[\"summary\"]\n",
    "    \n",
    "    # Print JSON in a readable format\n",
    "    print(\"📄 JSON OUTPUT:\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # Add job_id to the summary for complete JSON\n",
    "    complete_summary = {\"job_id\": summary_result.get('job_id', 'Unknown')}\n",
    "    complete_summary.update(summary)\n",
    "    \n",
    "    # Pretty print JSON\n",
    "    print(json.dumps(complete_summary, indent=2, ensure_ascii=False))\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a0da08cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "JOB DESCRIPTION SUMMARIZER - DEMO\n",
      "============================================================\n",
      "Processing Job ID: in-518379fd9e55e955\n",
      "Job Description Length: 4015 characters\n",
      "📋 JOB DESCRIPTION SUMMARY - ID: in-518379fd9e55e955\n",
      "============================================================\n",
      "📄 JSON OUTPUT:\n",
      "------------------------------\n",
      "{\n",
      "  \"job_id\": \"in-518379fd9e55e955\",\n",
      "  \"Job Information\": {\n",
      "    \"job_title\": \"Data Engineer\",\n",
      "    \"job_level\": \"Senior\"\n",
      "  },\n",
      "  \"Company Information\": {\n",
      "    \"company_name\": \"Macquarie\",\n",
      "    \"industry\": \"Financial Services\"\n",
      "  },\n",
      "  \"Location Information\": {\n",
      "    \"city\": null,\n",
      "    \"state\": null,\n",
      "    \"country\": null,\n",
      "    \"work_type\": \"hybrid\",\n",
      "    \"remote_flexibility\": \"partial\"\n",
      "  },\n",
      "  \"Compensation\": {\n",
      "    \"min_salary\": null,\n",
      "    \"max_salary\": null\n",
      "  },\n",
      "  \"Overview\": \"The Data Engineer will be responsible for building, implementing, and enhancing enterprise scale data solutions in a DevOps environment, ensuring high quality and low maintenance software solutions.\",\n",
      "  \"Responsibilities\": [\n",
      "    \"Design, develop, deploy, and support data assets.\",\n",
      "    \"Create templates, implementation methods, standards, and frameworks.\",\n",
      "    \"Develop high quality, low maintenance software solutions.\",\n",
      "    \"Coordinate requirements, schedules, activities, development, peer code reviews, and testing.\",\n",
      "    \"Ingest data from various sources including databases, APIs, and streaming data feeds.\"\n",
      "  ],\n",
      "  \"Requirements - Required\": {\n",
      "    \"skills\": [\n",
      "      \"Python\",\n",
      "      \"SQL\",\n",
      "      \"Data Definition Language\"\n",
      "    ],\n",
      "    \"tools\": [\n",
      "      \"BigQuery\",\n",
      "      \"Cloud Spanner\",\n",
      "      \"Cloud Functions\",\n",
      "      \"GCS\"\n",
      "    ],\n",
      "    \"experience\": {\n",
      "      \"years_min\": 5,\n",
      "      \"years_max\": 5,\n",
      "      \"level\": \"senior\"\n",
      "    },\n",
      "    \"qualifications\": [\n",
      "      \"Enterprise engineering experience in a mature cloud environment\",\n",
      "      \"Experience in building and deploying data lakes and data warehouses\",\n",
      "      \"Experience in developing code-based ETL/ELT data pipelines\"\n",
      "    ]\n",
      "  },\n",
      "  \"Requirements - Preferred\": {\n",
      "    \"skills\": [\n",
      "      \"Pub/Sub\",\n",
      "      \"Dataform\"\n",
      "    ],\n",
      "    \"tools\": [],\n",
      "    \"certifications\": [],\n",
      "    \"qualifications\": [\n",
      "      \"Experience with analytics and reporting tools\"\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "To use this script:\n",
      "1. Update 'parquet_file_path' with your actual parquet file path\n",
      "2. Update 'job_id_to_process' with the job ID you want to summarize\n",
      "3. Update column names if they're different from 'id' and 'JD'\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Initialize the summarizer\n",
    "    summarizer = JobDescriptionSummarizer()\n",
    "    \n",
    "    # Example: Process specific job from parquet file\n",
    "    print(\"=\" * 60)\n",
    "    print(\"JOB DESCRIPTION SUMMARIZER - DEMO\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Replace these with your actual values\n",
    "    parquet_file_path = \"id_jd_indeed.parquet\"  # Your parquet file path\n",
    "    job_id_to_process = \"in-518379fd9e55e955\"  # The specific job ID you want to process\n",
    "    \n",
    "    # Process the specific job description\n",
    "    result = summarizer.summarize_from_parquet(\n",
    "        parquet_file_path=parquet_file_path,\n",
    "        job_id=job_id_to_process,\n",
    "        id_column=\"id\",    # Change if your ID column has different name\n",
    "        jd_column=\"description\"     # Change if your JD column has different name\n",
    "    )\n",
    "    \n",
    "    # Print the result\n",
    "    print_job_summary(result)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"To use this script:\")\n",
    "    print(\"1. Update 'parquet_file_path' with your actual parquet file path\")\n",
    "    print(\"2. Update 'job_id_to_process' with the job ID you want to summarize\")\n",
    "    print(\"3. Update column names if they're different from 'id' and 'JD'\")\n",
    "    print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dfbd9a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tokens: 27\n",
      "Prompt Tokens: 14\n",
      "Completion Tokens: 13\n",
      "Total Cost (USD): $9.899999999999998e-06\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# Track tokens using callback\n",
    "with get_openai_callback() as cb:\n",
    "    result = llm.invoke(\"Summarize this job description...\")\n",
    "    \n",
    "    print(f\"Total Tokens: {cb.total_tokens}\")\n",
    "    print(f\"Prompt Tokens: {cb.prompt_tokens}\")\n",
    "    print(f\"Completion Tokens: {cb.completion_tokens}\")\n",
    "    print(f\"Total Cost (USD): ${cb.total_cost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4f33ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "846cd971",
   "metadata": {},
   "source": [
    "{\n",
    "  \"job_id\": \"in-a21984534d0b4317\",\n",
    "  \"job_title\": \"DevOps Engineer\",\n",
    "  \"job_level\": \"Mid-level\",\n",
    "  \n",
    "  \"company\": {\n",
    "    \"name\": \"TechCorp\",\n",
    "    \"industry\": \"Technology\"\n",
    "  },\n",
    "  \n",
    "  \"location\": {\n",
    "    \"city\": \"San Francisco\",\n",
    "    \"state\": \"CA\",\n",
    "    \"country\": \"USA\",\n",
    "    \"work_type\": \"on-site\",\n",
    "    \"remote_flexibility\": \"none\"\n",
    "  },\n",
    "  \n",
    "  \"compensation\": {\n",
    "    \"salary\": {\n",
    "      \"min\": 120000,\n",
    "      \"max\": 160000\n",
    "    }\n",
    "  },\n",
    "  \n",
    "  \"overview\": \"The DevOps Engineer position involves designing and implementing software development practices and tools to enhance system delivery, working closely with a client on-site.\",\n",
    "  \n",
    "  \"responsibilities\": [\n",
    "    \"Develop and implement CI/CD pipelines with a focus on containerization and continuous integration best practices.\",\n",
    "    \"Establish and maintain DevSecOps standards, tools, and governance.\",\n",
    "    \"Manage infrastructure and environments for reliability across production and non-production systems.\",\n",
    "    \"Collaborate with development and QA teams for efficient software delivery through automation.\",\n",
    "    \"Implement and maintain monitoring and logging solutions for system performance.\"\n",
    "  ],\n",
    "  \n",
    "  \"requirements\": {\n",
    "    \"required\": {\n",
    "      \"skills\": [\"AWS\", \"Kubernetes\", \"Docker\", \"GitLab\", \"Terraform\", \"Ansible\"],\n",
    "      \"tools\": [\"Rancher\", \"Bitbucket\", \"JFrog Artifactory\"],\n",
    "      \"experience\": {\n",
    "        \"years_min\": 3,\n",
    "        \"years_max\": 5,\n",
    "        \"level\": \"mid\"\n",
    "      },\n",
    "      \"qualifications\": [\n",
    "        \"Hands-on experience with Amazon Web Services (AWS)\",\n",
    "        \"Proficiency with Kubernetes and container orchestration\",\n",
    "        \"Experience with CI/CD tools (GitLab, Bitbucket)\",\n",
    "        \"Infrastructure as Code using Terraform\",\n",
    "        \"Configuration management with Ansible\"\n",
    "      ]\n",
    "    },\n",
    "    \"preferred\": {\n",
    "      \"skills\": [\"GCP\", \"Azure\", \"DevSecOps\"],\n",
    "      \"tools\": [\"Selenium Grid\", \"Cucumber\", \"Jira\", \"Confluence\"],\n",
    "      \"certifications\": [\"AWS Solutions Architect\", \"CKA\"],\n",
    "      \"qualifications\": [\n",
    "        \"Experience with additional CI/CD tools and practices\",\n",
    "        \"Familiarity with other cloud platforms\",\n",
    "        \"Knowledge of security best practices in DevOps\"\n",
    "      ]\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ls-academy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
